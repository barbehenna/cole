# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Compound decision method for multivariate linear models
#'
#' The function uses EM algorithm to solve multivariate linear regression problems 
#' \deqn{Y = XB + \epsilon}
#' both outcome \eqn{Y} and feature \eqn{X} are multi-dimensional. Users can set distinct residual estimations for different outcomes or set identical estimation for more robust results. Details can be found in \href{https://github.com/sdzhao/cole}{our paper}
#'
#' @param y \eqn{n x q} matrix of outcomes for training.
#' @param x \eqn{n x p} matrix of features for training. 
#' @param S \eqn{d x L} matrix of support points. If \eqn{L = p + 1}, then the first p columns are \eqn{\beta}s and the last column is the corresponding residual error estimates. If \eqn{L = p}, then each column of S is a vector of \eqn{\beta}s and argument min_s2 is required. \eqn{d = q x g} where g is the number of groups of support points. Support points can be estimated by other methods that solve multivariate linear regression. Eg. LASSO from glmnet, CMR from camel.
#' @param tol error tolerance for convergence of EM algorithm
#' @param maxit maximum number of allowable iterations
#' @param newx a \eqn{m x p} matrix corresponds to testing data.
#' @param min_s2 a positive number corresponds to minimal variance of estimated y. min_s2 is required when there are p columns in S
#'
#' @return
#' \item{f}{vector with \eqn{g x q} elements that describes the mixture of \eqn{\beta}s}
#' \item{esty}{\eqn{m x q} matrix of estimated y based on newx}
#'
#' @examples
#' \donttest{
#' ## generate data
#' p = 10
#' q = 5
#' n = 50
#' x = matrix(rnorm(n*p,0,10), n, p)
#' beta = matrix(rnorm(p*q,0,10), q, p)
#' e = matrix(rnorm(n*q,0,0.1),n,q)
#' y = x %*% t(beta) + e
#' s2 = matrix(rep(0.1,q), q, 1)
#' ## initialize parameters for EM algorithm 
#' tol = 0.001
#' maxit = 1000
#' x_test = matrix(rnorm(n*p,0,1), n, p)
#' ## set minimal variance estimation min_s2 = 0.1
#' output = comte(y=y, x=x, S=beta, tol=tol, maxit, p, q, n, x_test, min_s2=0.1)
#' ## use distinct variance from multivariate linear regression models
#' output = comte(y=y, x=x, S=cbind(beta,s2), tol=tol, maxit, p, q, n, x_test)
#' }
#'
#' @useDynLib cole
#' @export
comte <- function(y, x, S, tol = 0.000001, maxit = 100000L, min_s2 = NULL) {
    .Call('_cole_comte', PACKAGE = 'cole', y, x, S, tol, maxit, min_s2)
}

#' Prediction
#'
#' The function uses EM algorithm to solve multivariate linear regression problems 
#' \deqn{Y = XB + \epsilon}
#' both outcome \eqn{Y} and feature \eqn{X} are multi-dimensional. Users can set distinct residual estimations for different outcomes or set identical estimation for more robust results. Details can be found in \href{https://github.com/sdzhao/cole}{our paper}
#'
#' @param y \eqn{n x q} matrix of outcomes for training.
#' @param x \eqn{n x p} matrix of features for training. 
#' @param S \eqn{d x L} matrix of support points. If \eqn{L = p + 1}, then the first p columns are \eqn{\beta}s and the last column is the corresponding residual error estimates. If \eqn{L = p}, then each column of S is a vector of \eqn{\beta}s and argument min_s2 is required. \eqn{d = q x g} where g is the number of groups of support points. Support points can be estimated by other methods that solve multivariate linear regression. Eg. LASSO from glmnet, CMR from camel.
#' @param tol error tolerance for convergence of EM algorithm
#' @param maxit maximum number of allowable iterations
#' @param newx a \eqn{m x p} matrix corresponds to testing data.
#' @param min_s2 a positive number corresponds to minimal variance of estimated y. min_s2 is required when there are p columns in S
#'
#' @return
#' \item{f}{vector with \eqn{g x q} elements that describes the mixture of \eqn{\beta}s}
#' \item{esty}{\eqn{m x q} matrix of estimated y based on newx}
#'
#' @examples
#' \donttest{
#' ## generate data
#' p = 10
#' q = 5
#' n = 50
#' x = matrix(rnorm(n*p,0,10), n, p)
#' beta = matrix(rnorm(p*q,0,10), q, p)
#' e = matrix(rnorm(n*q,0,0.1),n,q)
#' y = x %*% t(beta) + e
#' s2 = matrix(rep(0.1,q), q, 1)
#' ## initialize parameters for EM algorithm 
#' tol = 0.001
#' maxit = 1000
#' x_test = matrix(rnorm(n*p,0,1), n, p)
#' ## set minimal variance estimation min_s2 = 0.1
#' output = comte(y=y, x=x, S=beta, tol=tol, maxit, p, q, n, x_test, min_s2=0.1)
#' ## use distinct variance from multivariate linear regression models
#' output = comte(y=y, x=x, S=cbind(beta,s2), tol=tol, maxit, p, q, n, x_test)
#' }
#'
#' @useDynLib cole
#' @export
predict_comte <- function(comte_obj, newx) {
    .Call('_cole_predict_comte', PACKAGE = 'cole', comte_obj, newx)
}

